import streamlit as st
import whisper
import tempfile
import os
import json
import gc
import torch
from datetime import datetime

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="ğŸ¤– AIéŸ³å£°æ–‡å­—èµ·ã“ã—ãƒ„ãƒ¼ãƒ«",
    page_icon="ğŸ¤",
    layout="wide",
    initial_sidebar_state="expanded"
)

# å…ƒã®index.htmlã¨åŒã˜ãƒ‡ã‚¶ã‚¤ãƒ³ã®CSS
st.markdown("""
<style>
    .stApp {
        font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
        background: linear-gradient(135deg, #667eea 0%, #764ba2 50%, #ff6b6b 100%);
        min-height: 100vh;
    }

    .main .block-container {
        max-width: 1400px;
        margin: 0 auto;
        background: rgba(255, 255, 255, 0.95);
        backdrop-filter: blur(10px);
        border-radius: 20px;
        padding: 30px;
        box-shadow: 0 20px 40px rgba(0, 0, 0, 0.1);
    }

    .title {
        text-align: center;
        color: #333;
        margin-bottom: 15px;
        font-size: 2.8em;
        font-weight: 300;
        background: linear-gradient(45deg, #667eea, #764ba2, #ff6b6b);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        background-clip: text;
    }

    .subtitle {
        text-align: center;
        color: #666;
        margin-bottom: 30px;
        font-size: 1.3em;
    }

    .ai-badge {
        display: flex;
        justify-content: center;
        gap: 15px;
        margin-bottom: 30px;
        flex-wrap: wrap;
    }

    .badge {
        padding: 8px 16px;
        border-radius: 20px;
        font-size: 0.9em;
        font-weight: 600;
        color: white;
    }

    .badge-ai { background: linear-gradient(45deg, #ff6b6b, #ff8e8e); }
    .badge-ml { background: linear-gradient(45deg, #4ecdc4, #44a08d); }
    .badge-dl { background: linear-gradient(45deg, #667eea, #764ba2); }
    .badge-realtime { background: linear-gradient(45deg, #feca57, #ff9ff3); }

    .upload-section {
        background: #f8f9fa;
        border-radius: 15px;
        padding: 30px;
        margin-bottom: 30px;
        border: 2px dashed #dee2e6;
    }

    .result-output {
        background: white;
        border: 1px solid #e9ecef;
        border-radius: 10px;
        padding: 25px;
        min-height: 200px;
        font-family: 'Noto Sans JP', sans-serif;
        font-size: 1.1em;
        line-height: 1.8;
        color: #333;
        white-space: pre-wrap;
        max-height: 400px;
        overflow-y: auto;
    }

    .stButton > button {
        background: linear-gradient(45deg, #667eea, #764ba2) !important;
        color: white !important;
        border: none !important;
        border-radius: 25px !important;
        padding: 12px 25px !important;
        font-size: 1em !important;
        font-weight: 600 !important;
        transition: all 0.3s ease !important;
    }

    .stButton > button:hover {
        transform: translateY(-2px) !important;
        box-shadow: 0 10px 20px rgba(102, 126, 234, 0.3) !important;
    }

    .memory-warning {
        background: linear-gradient(90deg, #ffc107 0%, #fd7e14 100%);
        color: white;
        padding: 1rem;
        border-radius: 10px;
        margin: 1rem 0;
        text-align: center;
    }

    .model-info {
        background: #e3f2fd;
        border: 1px solid #2196f3;
        border-radius: 10px;
        padding: 15px;
        margin: 10px 0;
    }
</style>
""", unsafe_allow_html=True)

# ãƒ¡ãƒ¢ãƒªåŠ¹ç‡çš„ãªãƒ¢ãƒ‡ãƒ«ç®¡ç†
class WhisperModelManager:
    def __init__(self):
        self.current_model = None
        self.current_model_size = None
        self.model_info = {
            "tiny": {"size": "39MB", "speed": "æœ€é«˜é€Ÿ", "accuracy": "åŸºæœ¬"},
            "base": {"size": "74MB", "speed": "é«˜é€Ÿ", "accuracy": "è‰¯å¥½"},
            "small": {"size": "244MB", "speed": "ä¸­é€Ÿ", "accuracy": "é«˜ç²¾åº¦"},
            "medium": {"size": "769MB", "speed": "ä½é€Ÿ", "accuracy": "ã‚ˆã‚Šé«˜ç²¾åº¦"},
        }
    
    def cleanup_memory(self):
        """ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        if self.current_model is not None:
            del self.current_model
            self.current_model = None
            self.current_model_size = None
        
        # GPU/CPUãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        try:
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
        except:
            pass
        
        # Python ã‚¬ãƒ™ãƒ¼ã‚¸ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³
        gc.collect()
    
    def load_model_safely(self, model_size):
        """å®‰å…¨ãªãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿"""
        try:
            # ãƒ¢ãƒ‡ãƒ«ãŒæ—¢ã«èª­ã¿è¾¼ã¾ã‚Œã¦ã„ã¦åŒã˜ã‚µã‚¤ã‚ºã®å ´åˆã¯ãã®ã¾ã¾ä½¿ç”¨
            if self.current_model is not None and self.current_model_size == model_size:
                return self.current_model
            
            # ãƒ¡ãƒ¢ãƒªåˆ¶é™ãƒã‚§ãƒƒã‚¯
            if model_size in ["large"]:
                st.error("âŒ largeãƒ¢ãƒ‡ãƒ«ã¯Streamlit Cloudã®ãƒ¡ãƒ¢ãƒªåˆ¶é™ã«ã‚ˆã‚Šåˆ©ç”¨ã§ãã¾ã›ã‚“")
                return None
            
            # æ—¢å­˜ãƒ¢ãƒ‡ãƒ«ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
            if self.current_model is not None:
                st.info("ğŸ”„ å‰ã®ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ¡ãƒ¢ãƒªã‹ã‚‰è§£æ”¾ä¸­...")
                self.cleanup_memory()
            
            # æ–°ã—ã„ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿
            with st.spinner(f"ğŸ¤– {model_size}ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ä¸­... ({self.model_info[model_size]['size']})"):
                self.current_model = whisper.load_model(model_size)
                self.current_model_size = model_size
            
            # æˆåŠŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
            info = self.model_info[model_size]
            st.success(f"âœ… {model_size}ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿å®Œäº†ï¼ ({info['size']}, {info['speed']}, {info['accuracy']})")
            
            return self.current_model
            
        except Exception as e:
            st.error(f"âŒ ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {str(e)}")
            self.cleanup_memory()
            return None
    
    def get_model_info(self, model_size):
        """ãƒ¢ãƒ‡ãƒ«æƒ…å ±ã‚’å–å¾—"""
        return self.model_info.get(model_size, {})

# ã‚°ãƒ­ãƒ¼ãƒãƒ«ãƒ¢ãƒ‡ãƒ«ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼
if 'model_manager' not in st.session_state:
    st.session_state.model_manager = WhisperModelManager()

def format_time(seconds):
    """ç§’ã‚’åˆ†:ç§’å½¢å¼ã«å¤‰æ›"""
    minutes = int(seconds // 60)
    seconds = int(seconds % 60)
    return f"{minutes:02d}:{seconds:02d}"

def safe_file_extension(filename):
    """å®‰å…¨ãªãƒ•ã‚¡ã‚¤ãƒ«æ‹¡å¼µå­ã‚’å–å¾—"""
    if not filename:
        return ".wav"
    ext = os.path.splitext(filename)[1].lower()
    supported_exts = ['.mp3', '.wav', '.m4a', '.flac', '.ogg', '.aac']
    return ext if ext in supported_exts else ".wav"

def transcribe_audio(audio_file, model_size, language, enable_timestamps, is_recording=False):
    """éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ–‡å­—èµ·ã“ã—ï¼ˆãƒ¡ãƒ¢ãƒªåŠ¹ç‡ç‰ˆï¼‰"""
    
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    try:
        # Step 1: ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ï¼ˆå®‰å…¨ç‰ˆï¼‰
        status_text.text("ğŸ¤– AIãƒ¢ãƒ‡ãƒ«æº–å‚™ä¸­...")
        progress_bar.progress(20)
        
        model = st.session_state.model_manager.load_model_safely(model_size)
        if model is None:
            return None, None
        
        # Step 2: ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
        status_text.text("ğŸ“ éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«æº–å‚™ä¸­...")
        progress_bar.progress(40)
        
        file_extension = ".wav" if is_recording else safe_file_extension(audio_file.name)
        
        with tempfile.NamedTemporaryFile(delete=False, suffix=file_extension) as tmp_file:
            try:
                file_content = audio_file.getvalue() if hasattr(audio_file, 'getvalue') else audio_file.read()
                tmp_file.write(file_content)
                tmp_file_path = tmp_file.name
            except Exception as e:
                st.error(f"ãƒ•ã‚¡ã‚¤ãƒ«æ›¸ãè¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
                return None, None
        
        # Step 3: æ–‡å­—èµ·ã“ã—è¨­å®š
        status_text.text("âš™ï¸ AIè§£æè¨­å®šä¸­...")
        progress_bar.progress(60)
        
        # ãƒ¡ãƒ¢ãƒªåŠ¹ç‡çš„ãªWhisperã‚ªãƒ—ã‚·ãƒ§ãƒ³
        options = {
            "language": None if language == "auto" else language,
            "verbose": False,
            "fp16": False,  # ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡å‰Šæ¸›
        }
        
        if enable_timestamps:
            options["word_timestamps"] = True
        
        # Step 4: AIè§£æå®Ÿè¡Œ
        status_text.text("ğŸ” AIéŸ³å£°è§£æä¸­...")
        progress_bar.progress(80)
        
        start_time = datetime.now()
        
        try:
            result = model.transcribe(tmp_file_path, **options)
        except Exception as whisper_error:
            st.error(f"âŒ éŸ³å£°è§£æã‚¨ãƒ©ãƒ¼: {str(whisper_error)}")
            return None, None
        
        processing_time = (datetime.now() - start_time).total_seconds()
        
        # Step 5: çµæœæ•´ç†
        status_text.text("ğŸ“ çµæœã‚’æ•´ç†ä¸­...")
        progress_bar.progress(100)
        
        transcribed_text = result.get("text", "").strip()
        if not transcribed_text:
            st.warning("âš ï¸ éŸ³å£°ã‹ã‚‰æ–‡å­—ã‚’æ¤œå‡ºã§ãã¾ã›ã‚“ã§ã—ãŸ")
            return None, None
        
        # çµæœãƒ‡ãƒ¼ã‚¿ä½œæˆ
        transcription_result = {
            "text": transcribed_text,
            "language": result.get("language", "unknown"),
            "processing_time": processing_time,
            "model_used": model_size,
            "char_count": len(transcribed_text),
            "word_count": len(transcribed_text.split()),
            "timestamp": datetime.now().isoformat(),
            "confidence": 1.0 - result.get("no_speech_prob", 0.0)
        }
        
        # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆæƒ…å ±
        segments = None
        if enable_timestamps and "segments" in result:
            segments = result["segments"]
        
        # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤
        try:
            os.unlink(tmp_file_path)
        except:
            pass
        
        # UIè¦ç´ ã‚’ã‚¯ãƒªã‚¢
        progress_bar.empty()
        status_text.empty()
        
        # æˆåŠŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
        st.success(f"ğŸ‰ æ–‡å­—èµ·ã“ã—å®Œäº†ï¼ å‡¦ç†æ™‚é–“: {processing_time:.2f}ç§’")
        
        return transcription_result, segments
        
    except Exception as e:
        progress_bar.empty()
        status_text.empty()
        st.error(f"âŒ å‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(e)}")
        
        # ã‚¨ãƒ©ãƒ¼æ™‚ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        try:
            if 'tmp_file_path' in locals():
                os.unlink(tmp_file_path)
        except:
            pass
        
        return None, None

def display_model_info(model_size):
    """ãƒ¢ãƒ‡ãƒ«æƒ…å ±ã‚’è¡¨ç¤º"""
    if model_size in st.session_state.model_manager.model_info:
        info = st.session_state.model_manager.model_info[model_size]
        st.markdown(f"""
        <div class="model-info">
            <strong>ğŸ“Š é¸æŠä¸­ã®ãƒ¢ãƒ‡ãƒ«: {model_size.upper()}</strong><br>
            ğŸ“¦ ã‚µã‚¤ã‚º: {info['size']} | âš¡ é€Ÿåº¦: {info['speed']} | ğŸ¯ ç²¾åº¦: {info['accuracy']}
        </div>
        """, unsafe_allow_html=True)

def display_memory_warning():
    """ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã®è­¦å‘Šã‚’è¡¨ç¤º"""
    st.markdown("""
    <div class="memory-warning">
        âš ï¸ ãƒ¡ãƒ¢ãƒªåŠ¹ç‡åŒ–ã®ãŸã‚ã€ãƒ¢ãƒ‡ãƒ«åˆ‡ã‚Šæ›¿ãˆæ™‚ã«å‰ã®ãƒ¢ãƒ‡ãƒ«ã‚’è‡ªå‹•è§£æ”¾ã—ã¾ã™<br>
        ğŸ’¡ å®‰å®šå‹•ä½œã®ãŸã‚ã€Œbaseã€ãƒ¢ãƒ‡ãƒ«ã‚’æ¨å¥¨ã—ã¾ã™
    </div>
    """, unsafe_allow_html=True)

def main():
    # ã‚¿ã‚¤ãƒˆãƒ«
    st.markdown("""
    <h1 class="title">ğŸ¤– AIéŸ³å£°æ–‡å­—èµ·ã“ã—ãƒ„ãƒ¼ãƒ«</h1>
    <div class="subtitle">å®‰å®šç‰ˆ - ãƒ¡ãƒ¢ãƒªåŠ¹ç‡åŒ–å¯¾å¿œ</div>
    """, unsafe_allow_html=True)

    # AIæ©Ÿèƒ½ãƒãƒƒã‚¸
    st.markdown("""
    <div class="ai-badge">
        <div class="badge badge-ai">ğŸ§  é©å¿œå­¦ç¿’AI</div>
        <div class="badge badge-ml">ğŸ“Š æ©Ÿæ¢°å­¦ç¿’åˆ†æ</div>
        <div class="badge badge-dl">ğŸ”¬ æ·±å±¤å­¦ç¿’å‡¦ç†</div>
        <div class="badge badge-realtime">âš¡ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è§£æ</div>
    </div>
    """, unsafe_allow_html=True)

    # ãƒ¡ãƒ¢ãƒªè­¦å‘Š
    display_memory_warning()

    # ã‚µã‚¤ãƒ‰ãƒãƒ¼è¨­å®š
    with st.sidebar:
        st.markdown("## âš™ï¸ è¨­å®šãƒ‘ãƒãƒ«")
        
        st.markdown("### ğŸ¤– AIãƒ¢ãƒ‡ãƒ«é¸æŠ")
        
        # ãƒ¢ãƒ‡ãƒ«é¸æŠï¼ˆå®‰å…¨ç‰ˆï¼‰
        model_size = st.selectbox(
            "å‡¦ç†é€Ÿåº¦ã¨ç²¾åº¦ã®ãƒãƒ©ãƒ³ã‚¹",
            options=["tiny", "base", "small", "medium"],  # largeã‚’é™¤å¤–
            index=1,  # baseã‚’ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
            help="å®‰å®šå‹•ä½œã®ãŸã‚ã€Œbaseã€ã‚’æ¨å¥¨ã—ã¾ã™",
            key="model_selector"
        )
        
        # ãƒ¢ãƒ‡ãƒ«æƒ…å ±è¡¨ç¤º
        display_model_info(model_size)
        
        # ãƒ¢ãƒ‡ãƒ«åˆ‡ã‚Šæ›¿ãˆè­¦å‘Š
        if st.session_state.model_manager.current_model_size and st.session_state.model_manager.current_model_size != model_size:
            st.warning(f"âš ï¸ ãƒ¢ãƒ‡ãƒ«ã‚’{st.session_state.model_manager.current_model_size}ã‹ã‚‰{model_size}ã«å¤‰æ›´ã—ã¾ã™")
        
        st.markdown("### ğŸŒ è¨€èªè¨­å®š")
        language = st.selectbox(
            "èªè­˜ã™ã‚‹è¨€èª",
            options=["auto", "ja", "en", "zh", "ko", "es", "fr", "de", "ru"],
            index=0,
            format_func=lambda x: {
                "auto": "ğŸ¤– è‡ªå‹•æ¤œå‡ºï¼ˆæ¨å¥¨ï¼‰",
                "ja": "ğŸ‡¯ğŸ‡µ æ—¥æœ¬èª",
                "en": "ğŸ‡ºğŸ‡¸ English",
                "zh": "ğŸ‡¨ğŸ‡³ ä¸­æ–‡",
                "ko": "ğŸ‡°ğŸ‡· í•œêµ­ì–´",
                "es": "ğŸ‡ªğŸ‡¸ EspaÃ±ol",
                "fr": "ğŸ‡«ğŸ‡· FranÃ§ais",
                "de": "ğŸ‡©ğŸ‡ª Deutsch",
                "ru": "ğŸ‡·ğŸ‡º Ğ ÑƒÑÑĞºĞ¸Ğ¹"
            }.get(x, x)
        )
        
        st.markdown("### â° è©³ç´°è¨­å®š")
        enable_timestamps = st.checkbox(
            "ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’æœ‰åŠ¹ã«ã™ã‚‹", 
            value=True,
            help="éŸ³å£°ã®æ™‚é–“åŒºåˆ‡ã‚Šæƒ…å ±ã‚’å–å¾—ã—ã¾ã™"
        )
        
        # ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ãƒœã‚¿ãƒ³
        st.markdown("### ğŸ§¹ ãƒ¡ãƒ¢ãƒªç®¡ç†")
        if st.button("ğŸ—‘ï¸ ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—", help="ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ¡ãƒ¢ãƒªã‹ã‚‰è§£æ”¾ã—ã¾ã™"):
            st.session_state.model_manager.cleanup_memory()
            st.success("âœ… ãƒ¡ãƒ¢ãƒªã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã—ã¾ã—ãŸ")
            st.rerun()
        
        # ç¾åœ¨ã®ãƒ¡ãƒ¢ãƒªçŠ¶æ…‹è¡¨ç¤º
        if st.session_state.model_manager.current_model_size:
            st.info(f"ğŸ“¦ èª­ã¿è¾¼ã¿æ¸ˆã¿: {st.session_state.model_manager.current_model_size}ãƒ¢ãƒ‡ãƒ«")
        else:
            st.info("ğŸ“¦ ãƒ¢ãƒ‡ãƒ«æœªèª­ã¿è¾¼ã¿")

    # ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„
    col1, col2 = st.columns([1, 1])
    
    with col1:
        st.markdown("## ğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")
        
        uploaded_file = st.file_uploader(
            "éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠ",
            type=['wav', 'mp3', 'm4a', 'flac', 'ogg', 'aac'],
            help="WAV, MP3, M4Aå½¢å¼ã‚’æ¨å¥¨ï¼ˆ25MBä»¥ä¸‹ï¼‰"
        )
        
        if uploaded_file is not None:
            file_size = len(uploaded_file.getvalue()) / (1024 * 1024)
            
            if file_size > 25:
                st.error("âŒ ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºãŒ25MBã‚’è¶…ãˆã¦ã„ã¾ã™")
            else:
                st.success(f"âœ… ãƒ•ã‚¡ã‚¤ãƒ«é¸æŠæ¸ˆã¿: {uploaded_file.name} ({file_size:.1f}MB)")
                
                # éŸ³å£°ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
                if uploaded_file.type.startswith('audio/'):
                    st.audio(uploaded_file.getvalue())
        
        # æ–‡å­—èµ·ã“ã—å®Ÿè¡Œãƒœã‚¿ãƒ³
        if st.button("ğŸš€ æ–‡å­—èµ·ã“ã—é–‹å§‹", type="primary", use_container_width=True):
            if uploaded_file is not None:
                file_size = len(uploaded_file.getvalue()) / (1024 * 1024)
                if file_size <= 25:
                    result, segments = transcribe_audio(uploaded_file, model_size, language, enable_timestamps)
                    if result:
                        st.session_state['result'] = result
                        st.session_state['segments'] = segments
                        st.rerun()
                else:
                    st.error("âŒ ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºãŒ25MBã‚’è¶…ãˆã¦ã„ã¾ã™")
            else:
                st.error("âŒ éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„")

    with col2:
        st.markdown("## ğŸ¤ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŒ²éŸ³")
        
        st.info("ğŸ’¡ ãƒã‚¤ã‚¯éŒ²éŸ³æ©Ÿèƒ½ï¼ˆãƒ¡ãƒ¢ãƒªåŠ¹ç‡åŒ–ç‰ˆï¼‰")
        
        audio_value = st.audio_input("ğŸ™ï¸ éŒ²éŸ³ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¦è©±ã—ã‹ã‘ã¦ãã ã•ã„")
        
        if audio_value is not None:
            st.success("âœ… éŒ²éŸ³å®Œäº†ï¼")
            
            if st.button("ğŸ” éŒ²éŸ³éŸ³å£°ã‚’æ–‡å­—èµ·ã“ã—", use_container_width=True, type="secondary"):
                result, segments = transcribe_audio(audio_value, model_size, language, enable_timestamps, is_recording=True)
                if result:
                    st.session_state['result'] = result
                    st.session_state['segments'] = segments
                    st.rerun()

    # çµæœè¡¨ç¤ºã‚¨ãƒªã‚¢
    st.markdown("---")
    
    if 'result' in st.session_state and st.session_state['result']:
        result = st.session_state['result']
        segments = st.session_state.get('segments')
        
        # çµ±è¨ˆæƒ…å ±
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("ğŸ“„ æ–‡å­—æ•°", result['char_count'])
        with col2:
            st.metric("ğŸ“ å˜èªæ•°", result['word_count'])
        with col3:
            st.metric("â±ï¸ å‡¦ç†æ™‚é–“", f"{result['processing_time']:.2f}ç§’")
        with col4:
            st.metric("ğŸŒ æ¤œå‡ºè¨€èª", result['language'].upper())
        
        # ã‚¿ãƒ–è¡¨ç¤º
        tab1, tab2 = st.tabs(["ğŸ“ æ–‡å­—èµ·ã“ã—çµæœ", "â° ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ä»˜ã"])
        
        with tab1:
            st.markdown("### ğŸ“ æ–‡å­—èµ·ã“ã—çµæœ")
            st.markdown(f"""
            <div class="result-output">
                {result['text']}
            </div>
            """, unsafe_allow_html=True)
            
            # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
            st.download_button(
                "ğŸ’¾ ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                data=result['text'],
                file_name=f"transcription_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt",
                mime="text/plain",
                use_container_width=True
            )
        
        with tab2:
            if segments and enable_timestamps:
                st.markdown("### â° ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ä»˜ãã‚»ã‚°ãƒ¡ãƒ³ãƒˆ")
                
                for segment in segments:
                    start_time = segment.get("start", 0)
                    end_time = segment.get("end", 0)
                    text = segment.get("text", "").strip()
                    
                    start_formatted = format_time(start_time)
                    end_formatted = format_time(end_time)
                    
                    st.markdown(f"""
                    <div style="background: #f8f9fa; padding: 15px; margin: 10px 0; border-radius: 10px; border-left: 4px solid #667eea;">
                        <strong>[{start_formatted} - {end_formatted}]</strong><br>
                        {text}
                    </div>
                    """, unsafe_allow_html=True)
            else:
                st.info("ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—æ©Ÿèƒ½ã‚’æœ‰åŠ¹ã«ã—ã¦æ–‡å­—èµ·ã“ã—ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„")
    
    else:
        st.markdown("## ğŸ“ çµæœè¡¨ç¤ºã‚¨ãƒªã‚¢")
        st.info("éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã¾ãŸã¯éŒ²éŸ³ã—ã¦ã€æ–‡å­—èµ·ã“ã—ã‚’é–‹å§‹ã—ã¦ãã ã•ã„")
    
    # ã‚¯ãƒªã‚¢ãƒœã‚¿ãƒ³
    if st.button("ğŸ—‘ï¸ å…¨ã¦ã‚¯ãƒªã‚¢", use_container_width=True):
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚’ã‚¯ãƒªã‚¢
        for key in ['result', 'segments']:
            if key in st.session_state:
                del st.session_state[key]
        
        # ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        st.session_state.model_manager.cleanup_memory()
        st.success("âœ… å…¨ã¦ã‚¯ãƒªã‚¢ã—ã¾ã—ãŸ")
        st.rerun()

if __name__ == "__main__":
    main()
